from sklearn.cluster import KMeans, DBSCAN
from sklearn.mixture import GaussianMixture
from skopt import BayesSearchCV
from skopt.space import Integer, Real, Categorical
from sklearn.metrics import silhouette_score, make_scorer
import pandas as pd
import numpy as np

# Dataset size parameters for constraints
min_cluster_size = 0.0075  # 0.75% of the total data
max_cluster_size = 0.6     # 60% of the total data
n_samples = X_scaled.shape[0]

# Custom Scorer with Cluster Size Penalties
def silhouette_with_penalty(estimator, X):
    labels = estimator.fit_predict(X)
    unique, counts = np.unique(labels, return_counts=True)
    cluster_sizes = counts / n_samples  # Cluster sizes as proportions of the dataset

    # Calculate Silhouette Score only if we have more than one cluster
    if len(set(labels)) > 1:
        ss = silhouette_score(X, labels)
    else:
        return -1  # Return low score if only one cluster

    # Apply penalties if clusters are outside the desired size range
    penalty = 0
    for size in cluster_sizes:
        if size < min_cluster_size or size > max_cluster_size:
            penalty += 0.1  # Increment penalty for each offending cluster

    return ss - penalty  # Subtract penalty from Silhouette Score

scorer = make_scorer(silhouette_with_penalty, greater_is_better=True)

# 1. GMM Optimization with Cluster Constraints
gmm_param_grid = {
    "n_components": Integer(4, 8),
    "covariance_type": Categorical(['full', 'tied', 'diag', 'spherical']),
    "tol": Real(1e-4, 1e-2, prior='log-uniform'),
    "max_iter": Integer(100, 500)
}

gmm_opt = BayesSearchCV(
    GaussianMixture(random_state=0),
    gmm_param_grid,
    n_iter=50,
    scoring=scorer,
    cv=3,
    n_jobs=-1,
    random_state=0
)
gmm_opt.fit(X_scaled)
gmm_best_params = gmm_opt.best_params_
gmm_best_ss = gmm_opt.best_score_

# 2. KMeans Optimization with Cluster Constraints
kmeans_param_grid = {
    "n_clusters": Integer(4, 8),
    "tol": Real(1e-4, 1e-2, prior='log-uniform'),
    "max_iter": Integer(100, 500)
}

kmeans_opt = BayesSearchCV(
    KMeans(random_state=0),
    kmeans_param_grid,
    n_iter=50,
    scoring=scorer,
    cv=3,
    n_jobs=-1,
    random_state=0
)
kmeans_opt.fit(X_scaled)
kmeans_best_params = kmeans_opt.best_params_
kmeans_best_ss = kmeans_opt.best_score_

# 3. DBSCAN Optimization with Eps and Min Samples Constraints
dbscan_param_grid = {
    "eps": Real(0.1, 5.0, prior='log-uniform'),
    "min_samples": Integer(2, 20)
}

dbscan_opt = BayesSearchCV(
    DBSCAN(),
    dbscan_param_grid,
    n_iter=50,
    scoring=scorer,
    cv=3,
    n_jobs=-1,
    random_state=0
)
dbscan_opt.fit(X_scaled)
dbscan_best_params = dbscan_opt.best_params_
dbscan_best_ss = dbscan_opt.best_score_

# Compile and display results
results = pd.DataFrame({
    "Model": ["Gaussian Mixture Model (GMM)", "KMeans", "DBSCAN"],
    "Best Parameters": [gmm_best_params, kmeans_best_params, dbscan_best_params],
    "Best Silhouette Score (SS)": [gmm_best_ss, kmeans_best_ss, dbscan_best_ss]
})

print(results)
