import pandas as pd
import random
import numpy as np

# Example Input DataFrame
df = pd.DataFrame({
    "knowledge": [
        "The Eiffel Tower is located in Paris.",
        "Albert Einstein developed the theory of relativity.",
        "The Great Wall of China is in China.",
        "The Taj Mahal is in India.",
        "Mount Everest is the tallest mountain on Earth.",
        "The Statue of Liberty is in New York City.",
        "The Amazon Rainforest is the largest tropical rainforest."
    ],
    "question": [
        "Where is the Eiffel Tower?",
        "Who developed the theory of relativity?",
        "Where is the Great Wall of China?",
        "Where is the Taj Mahal?",
        "What is the tallest mountain on Earth?",
        "Where is the Statue of Liberty?",
        "What is the largest tropical rainforest?"
    ],
    "answer": [
        "Paris",
        "Albert Einstein",
        "China",
        "India",
        "Mount Everest",
        "New York City",
        "The Amazon Rainforest"
    ]
})

# Step 1: Generate synthetic fat knowledge
num_samples = 1000  # Total desired samples
num_fat_knowledge = num_samples // 2  # Each fat knowledge will have 1 legit + 1 hallucinated

# Randomly sample 5â€“10 knowledge snippets and combine them
fat_knowledge_list = [
    " ".join(random.sample(df["knowledge"].tolist(), random.randint(5, 10)))
    for _ in range(num_fat_knowledge)
]

# Randomly insert relevant knowledge into the fat knowledge
relevant_indices = np.random.randint(0, len(df), num_fat_knowledge)
relevant_snippets = df.iloc[relevant_indices]["knowledge"].tolist()

# Insert relevant knowledge into random positions in the fat knowledge
final_fat_knowledge = []
for i, fat_knowledge in enumerate(fat_knowledge_list):
    knowledge_parts = fat_knowledge.split(" ")
    insert_position = random.randint(0, len(knowledge_parts))
    knowledge_parts.insert(insert_position, relevant_snippets[i])
    final_fat_knowledge.append(" ".join(knowledge_parts))

# Step 2: Generate legitimate and hallucinated samples
questions = df.iloc[relevant_indices]["question"].tolist()
legit_answers = df.iloc[relevant_indices]["answer"].tolist()

# Create legitimate samples
df_legit = pd.DataFrame({
    "fat_knowledge": final_fat_knowledge,
    "question": questions,
    "answer": legit_answers,
    "label": "legit"
})

# Create hallucinated samples
df_hallucinated = pd.DataFrame({
    "fat_knowledge": final_fat_knowledge,
    "question": questions,
    "answer": ["This is a hallucinated answer."] * num_fat_knowledge,
    "label": "hallucinated"
})

# Combine both datasets
df_synthetic = pd.concat([df_legit, df_hallucinated], ignore_index=True)

# Save or preview the dataset
df_synthetic.to_csv("synthetic_fat_knowledge.csv", index=False)
print(df_synthetic.head())
print(f"Total samples: {len(df_synthetic)}")
