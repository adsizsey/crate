from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
import numpy as np

# Encode target labels using label_to_ind_dict
y_train = train_df["Intent"].map(label_to_ind_dict).values

# Train pipeline
pipeline = make_pipeline(
    TfidfVectorizer(ngram_range=(1, 2), max_features=10000),
    LogisticRegression(max_iter=1000, solver="lbfgs", multi_class="ovr")
)

pipeline.fit(train_df["Utterance"], y_train)

# Predict on all datasets
for name, df in datasets.items():
    X = df["Utterance"]
    probs = pipeline.predict_proba(X)
    preds = np.argmax(probs, axis=1)

    df["BaselinePrediction"] = [ind_to_label_dict[i] for i in preds]
    df["BaselineConfidence"] = probs.max(axis=1)
    
    datasets[name] = df
